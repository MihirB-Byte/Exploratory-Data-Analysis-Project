{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis\n",
    "\n",
    "Analyze temporal patterns and trends in accident occurrence over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create daily time series\n",
    "daily_accidents = df.groupby('Start_Time').size().reset_index()\n",
    "daily_accidents.columns = ['Date', 'Count']\n",
    "daily_accidents.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot time series with trend\n",
    "plt.figure(figsize=(15, 6))\n",
    "daily_accidents.plot()\n",
    "plt.title('Daily Accident Counts')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Accidents')\n",
    "plt.show()\n",
    "\n",
    "# Add rolling averages\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=daily_accidents.index, y=daily_accidents['Count'],\n",
    "                        mode='lines', name='Daily Accidents'))\n",
    "\n",
    "# Add 7-day moving average\n",
    "rolling_7 = daily_accidents['Count'].rolling(window=7).mean()\n",
    "fig.add_trace(go.Scatter(x=daily_accidents.index, y=rolling_7,\n",
    "                        mode='lines', name='7-day Moving Average',\n",
    "                        line=dict(color='red')))\n",
    "\n",
    "# Add 30-day moving average\n",
    "rolling_30 = daily_accidents['Count'].rolling(window=30).mean()\n",
    "fig.add_trace(go.Scatter(x=daily_accidents.index, y=rolling_30,\n",
    "                        mode='lines', name='30-day Moving Average',\n",
    "                        line=dict(color='green')))\n",
    "\n",
    "fig.update_layout(title='Accident Trends with Moving Averages',\n",
    "                 xaxis_title='Date',\n",
    "                 yaxis_title='Number of Accidents')\n",
    "fig.show()\n",
    "\n",
    "# Seasonal decomposition\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Resample to daily frequency if needed\n",
    "daily_series = daily_accidents['Count'].resample('D').sum()\n",
    "\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(daily_series, period=365)\n",
    "\n",
    "# Plot decomposition\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "decomposition.observed.plot(ax=ax1)\n",
    "ax1.set_title('Observed')\n",
    "decomposition.trend.plot(ax=ax2)\n",
    "ax2.set_title('Trend')\n",
    "decomposition.seasonal.plot(ax=ax3)\n",
    "ax3.set_title('Seasonal')\n",
    "decomposition.resid.plot(ax=ax4)\n",
    "ax4.set_title('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering Analysis\n",
    "\n",
    "Perform spatial clustering to identify accident hotspots and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Prepare data for clustering\n",
    "X = df[['Start_Lat', 'Start_Lng']].copy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Find optimal number of clusters\n",
    "silhouette_scores = []\n",
    "K = range(2, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, silhouette_scores, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs Number of Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Perform clustering with optimal k\n",
    "optimal_k = K[np.argmax(silhouette_scores)]\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize clusters on map\n",
    "cluster_map = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "# Create a color map for clusters\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred',\n",
    "          'lightred', 'beige', 'darkblue', 'darkgreen']\n",
    "\n",
    "# Add points colored by cluster\n",
    "for idx, row in df.sample(10000).iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Start_Lat'], row['Start_Lng']],\n",
    "        radius=3,\n",
    "        color=colors[row['Cluster'] % len(colors)],\n",
    "        fill=True\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "display(cluster_map)\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "cluster_stats = df.groupby('Cluster').agg({\n",
    "    'Severity': 'mean',\n",
    "    'Duration': 'mean',\n",
    "    'Start_Lat': 'mean',\n",
    "    'Start_Lng': 'mean',\n",
    "    'ID': 'count'\n",
    "}).round(2)\n",
    "\n",
    "cluster_stats.columns = ['Avg Severity', 'Avg Duration', 'Center Lat', \n",
    "                        'Center Lng', 'Number of Accidents']\n",
    "display(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictive Modeling\n",
    "\n",
    "Build and evaluate models to predict accident severity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare features for modeling\n",
    "feature_columns = ['Hour', 'DayOfWeek', 'Month', 'IsWeekend',\n",
    "                  'Temperature(F)', 'Humidity(%)', 'Pressure(in)',\n",
    "                  'Visibility(mi)', 'Wind_Speed(mph)']\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df['Weather_Encoded'] = le.fit_transform(df['Weather_Condition'])\n",
    "df['Sunrise_Sunset_Encoded'] = le.fit_transform(df['Sunrise_Sunset'])\n",
    "feature_columns.extend(['Weather_Encoded', 'Sunrise_Sunset_Encoded'])\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['Severity']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "plt.title('Feature Importance for Severity Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Dashboard\n",
    "\n",
    "Create an interactive dashboard to explore accident patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive dashboard using plotly\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create the dashboard layout\n",
    "dashboard = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=('Accidents by Hour', 'Severity Distribution',\n",
    "                   'Weather Impact', 'Monthly Trend',\n",
    "                   'Accident Hotspots', 'Feature Importance'),\n",
    "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "           [{\"type\": \"scattermapbox\", \"colspan\": 2}, None]]\n",
    ")\n",
    "\n",
    "# 1. Accidents by Hour\n",
    "hourly_counts = df.groupby('Hour').size()\n",
    "dashboard.add_trace(\n",
    "    go.Scatter(x=hourly_counts.index, y=hourly_counts.values,\n",
    "               mode='lines+markers', name='Hourly Pattern'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Severity Distribution\n",
    "severity_counts = df['Severity'].value_counts()\n",
    "dashboard.add_trace(\n",
    "    go.Pie(labels=severity_counts.index, values=severity_counts.values,\n",
    "           name='Severity'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Weather Impact\n",
    "weather_counts = df['Weather_Condition'].value_counts().head(10)\n",
    "dashboard.add_trace(\n",
    "    go.Bar(x=weather_counts.index, y=weather_counts.values,\n",
    "           name='Weather Conditions'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Monthly Trend\n",
    "monthly_counts = df.groupby('Month').size()\n",
    "dashboard.add_trace(\n",
    "    go.Scatter(x=monthly_counts.index, y=monthly_counts.values,\n",
    "               mode='lines+markers', name='Monthly Trend'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# 5. Accident Hotspots\n",
    "dashboard.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=df['Start_Lat'].sample(1000),\n",
    "        lon=df['Start_Lng'].sample(1000),\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color='red'),\n",
    "        name='Accidents'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "dashboard.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=True,\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        zoom=3,\n",
    "        center=dict(lat=37.0902, lon=-95.7129)\n",
    "    ),\n",
    "    title_text=\"US Accidents Analysis Dashboard\"\n",
    ")\n",
    "\n",
    "dashboard.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
